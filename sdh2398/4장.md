# 커넥션 관리

### TCP 커넥션

전 세계 모든 HTTP 통신은 패킷 교환 네트워크 프로토콜들의 집합인 TCP/IP를 통해 이루어진다.
* 커넥션이 맺어지면 클라와 서버 컴퓨터 간에 주고받는 메시지들은 손실 혹은 손상되거나 순서가 바뀌지 않고 안전하게 전달

URL을 입력받은 브라우저는 다음과 같은 단계를 수행한다.
* URL에서 호스트명을 추출
* 호스트 명에 대한 IP 주소를 찾는다.
* 포트 번호(80)를 얻는다.
* TCP 커넥션을 생성
* 서버로 요청 메시지를 보낸다.
* 서버에서 온 응답 메시지를 읽는다.
* 커넥션을 끊는다.

#### 신뢰할 수 있는 데이터 전송 통로인 TCP
HTTP 커넥션은 몇몇 사용 규칙을 제외하고는 TCP 커넥션에 불과하다.
* TCP 커넥션은 인터넷을 안정적으로 연결

#### TCP 스트림은 세그먼트로 나뉘어 IP패킷을 통해 전송된다.
* TCP는 IP 패킷(IP 데이터그램)이라고 불리는 작은 조각을 통해 데이터를 전송
* IP 패킷은 다음을 포함
    * IP 패킷 헤더(보통 20바이트)
        * 발신자와 목적지 IP주소
        * 크기
        * 기타 플래그
    * TCP 세그먼트 헤더(보통 20바이트)
        * TCP 포트 번호
        * TCP 제어 플래그
        * 데이터 순서와 무결성을 검사하기 위해 사용되는 숫자들
    * TCP 데이터 조각(0 혹은 그 이상의 바이트)

#### TCP 커넥션 유지하기
컴퓨터는 항상 TCP 커넥션을 여러 개 가지고 있다.
* TCP는 포트 번호를 통해서 이런 여러 개의 커넥션을 유지
* <발신지 IP주소, 발신지 포트, 수신지 IP주소, 수신지 포트>
* 서로 다른 커넥션은 주소 구성요소 일부가 같을 순 있지만 모든 값이 같을 순 없다.

#### TCP 소켓 프로그래밍
운영체제는 TCP 커넥션의 생성과 관련된 여러 기능을 제공한다.
* 소켓 API는 개발자에게 TCP와 IP의 세부사항들을 숨긴다.
* 소켓 API를 사용하면, TCP 종단(endpoint) 데이터 구조를 생성하고, 원격 서버의 TCP 종단에 데이터 구를 연결하여 데이터 스트림을 읽고 쓸 수 있다.

### TCP의 성능에 대한 고려
HTTP는 TCP 바로 위에 있는 계층이기 때문에 HTTP 트랜잭션의 성능은 그 아래 계층인 TCP 성능에 영향을 받는다.

#### HTTP 트랜잭션 지연
트랜잭션을 처리하는 시간은 TCP 커넥션을 설정하고, 요청을 전송하고, 응답 메시지를 보내는 것에 비하면 상당히 짧다.
* 클라가 서버에 너무 많은 데이터를 내려받거나 복잡하고 동적인 자원들을 실행하지 않는 한, 대부분의 HTTP 지연은 TCP 네트워크 지연 때문에 발생

HTTP 트랜잭션을 지연시키는 원인은 여러 가지가 있다.
* 클라는 URI에서 웹 서버의 IP 주소와 포트 번호를 알아내야 한다.
    *  최근에 방문한 적이 없으면, DNS 이름 분석을 통해 호스트 명을 IP 주소로 변환
    * DNS 캐시가 되어 있다면 바로 IP를 찾을 수 있다.
* 커넥션 설정 시간은 새로운 TCP 커넥션에서 항상 발생
    * 클라가 TCP 커넥션 요청을 서버에 보내고 커넥션 허가 응답을 회신하기를 기다림
* HTTP 요청을 새로 생성된 TCP 파이프를 통해 전송
    * 요청 메시지가 인터넷을 통해 전달되고 서버에 의해서 처리되는 데까지는 시간이 소요
* 웹 서버가 HTTP 응답을 보내는 시간 소요

TCP 네트워크 지연은 여러가지 원인에 의해 크게 달라진다.
* 하드웨어 성능
* 네트워크와 서버의 전송 속도
* 요청과 응답 메시지의 크기
* 클라와 서버 간의 거리
* TCP 프로토콜의 기술적인 복잡성

#### 성능 관련 중요 요소
고성능의 HTTP 소프트웨어를 개발하고 있다면, 다음 항목 각각을 모두 이해해야 한다.
* TCP 커넥션의 핸드셰이크 설정
* 인터넷의 혼잡을 제어하기 위한 TCP의 느린 시작(slow-start)
* 데이터를 한데 모아 한 번에 전송하기 위한 네이글(nagle) 알고리즘
* TCP의 편승(piggyback) 확인응답(acknowledgment)을 위한 확인응답 지연 알고리즘
* TIME_WAIT 지연과 포트 고갈

#### TCP 커넥션 핸드셰이크 지연
어떤 데이터든 TCP 커넥션을 열 때면, 커넥션을 맺기 위한 조건을 맞추기 위해 연속적으로 IP 패킷을 교환한다.
* 작은 데이터 전송에 커넥션이 사용된다면 이런 패킷 교환은 HTTP 성능을 크게 저하시킨다.

TCP 커넥션이 핸드셰이크 하는 순서
* ’SYN’이라는 플래그를 가진 작은 TCP 패킷(40~60바이트)을 서버에 보낸다.
* 서버는 몇 가지 커넥션 매개변수를 산출하고, 커넥션 요청을 받아들임을 의미하는 ’SYN’, ‘ACK’플래그를 포함한 TCP 패킷을 클라에 보낸다.
* 마지막으로 클라는 잘 맺어졌음을 알리는 ‘ACK’ 확인 응답을 보낸다.
    * 오늘날에는 클라가 이 확인 응답 패킷과 함께 데이터를 보낼 수 있다.

HTTP 트랜잭션이 아주 큰 데이터를 주고받지 않는 평범한 경우에는 핸드셰이크가 눈에 띄는 지연을 발생시킨다.
* TCP의 ACK 패킷은 HTTP 요청 메시지 전체를 전달할 수 있을 만큼 큰 경우가 많다.
* 많은 HTTP 응답 메시지는 하나의 IP 패킷에도 담길 수 있다.
* 크기가 작은 HTTP 트랜잭션은 50% 이상의 시간을 TCP를 구성하는 데 쓴다.
* 이러한 지연을 제거하기 위해 HTTP가 이미 존재하는 커넥션을 재활용한다.

#### 확인응답 지연
인터넷 자체가 패킷 전송을 완벽하게 보장하지는 않기 떄문에, TCP는 성공적인 데이터 전송을 보장하기 위해 자체적인 확인 체계를 가진다.
* 인터넷 라우터는 과부하가 걸렸을 때 패킷을 마음대로 파기

각 TCP 세그먼트는 순번과 데이터 무결성 체크섬을 가진다.
* 각 세그먼트의 수신자는 세그먼트를 온전히 받으면 작은 확인응답 패킷을 송신자에게 반환
* 특정 시간 안에 확인응답 메시지를 받지 못하면 데이터를 다시 전송

확인응답은 그 크기가 작기 때문에, TCP는 같은 방향으로 송출되는 데이터 패킷에 확인응답을 ‘편승’시킨다.
* 확인응답이 같은 방향으로 가는 데이터 패킷에 편승되는 경우를 늘리기 위해 확인응답 지연 알고리즘을 구현
* 특정 시간동안(0.1~0.2초) 버퍼에 저장해 두고, 확인응답을 편승시키기 위한 송출 데이터 패킷을 찾는다.
* 일정시간동안 찾지 못하면 별도의 패킷으로 전송

요청, 응답 두 가지 형식으로만 이루어진 HTTP 동작 방식은, 편승한 기회를 감소시킨다.
* 편승할 패킷이 많지 않기 때문에 지연이 발생
* 운영체제에 따라 다르지만 관련 기능을 수정하거나 비활성화 할 수 있다.

#### TCP 느린 시작(slow start)
TCP의 전송 속도는 TCP 커넥션이 만들어진 지 얼마나 지났는지에 따라 달라질 수 있다.
* 시간이 지나면서 자체적으로 ‘튜닝’된다.
* 처음에는 최대 속도를 제한하고 성공적으로 전송됨에 따라서 속도 제한을 높여나간다.
    * 간단히 말해, 패킷이 성공적으로 전달되는 시점에 송신자는 추가로 2개의 패킷을 더 전송할 수 있는 권한을 얻는다.
    * 이를 ‘혼잡 윈도를 연다’라고 한다.
* 이렇게 조율하는 것을 느린 시작이라고 한다.
* 급작스러운 부하와 혼잡을 방지하는데 사용

이 흔잡제어 기능 때문에, 새로운 커넥션은 이미 어느 정도 데이터를 주고받은 ‘튜닝’된 커넥션보다 느리다.
* ‘튜닝’된 커넥션이 더 빠르기 때문에 이미 존재하는 커넥션을 재사용하는 기능이 있다.

#### 네이글(Nagle) 알고리즘과 TCP_NODELAY
1바이트의 작은 크기의 데이터도 TCP 스택으로 전송할 수 있도록, 데이터 스트림 인터페이스를 제공한다. 
* 하지만 각 TCP 세그먼트는 40바이트 상당의 플래그와 헤더를 포함하여 전송
* 작은 크기의 데이터를 포함한 많은 수의 패킷을 전송한다면 성능은 크게 떨어진다.

네이글 알고리즘은 패킷을 전송하기 전에 많은 양의 TCP 데이터를 한 개의 덩어리로 합친다.
* 세그먼트가 최대 크기가 되지 않으면 전송을 하지 않는다.
* 다만 전송되고 나서 확인응답을 기다리던 패킷이 확인응답을 받았거나 전송하기 충분할 만큼 쌓이면 버퍼에 쌓인 데이터가 전송
    * 다른 패킷들이 아직 전송중이면 버퍼에 저장

네이글 알고리즘은 여러 문제를 발생시킨다.
* 크기가 작은 메시지는 패킷을 채우지 못하기 때문에, 앞으로 생기지 않을지 모르는 데이터를 기다리며 지연
* 확인응답 지연과 함께 쓰일경우 형편없이 동작
    * 네이글 알고리즘은 확인응답이 도착할 때까지 데이터 전송을 멈추고, 확인응답 지연 알고리즘은 확인응답을 100~200밀리초 지연시킨다.

HTTP 애플리케이션은 성능 향상을 위해 HTTP 스택에 TCP_NODELAY 파라미터 값을 설정하여 비활성화하기도 한다.
* 이 설정을 했다면, 작은 크기의 패킷이 너무 많이 생기지 않도록 큰 크기의 데이터 덩어리를 만들어야 한다.

#### TIME_WAIT의 누적과 포트 고갈
TIME_WAIT 포트 고갈은 성능 측정 시에 심각한 성능 저하를 발생시키지만, 보통 실제 상황에서는 문제를 발생시키지 않는다.

TCP 커넥션의 종단에서 TCP 커넥션을 끊으면, 종단에서는 커넥션의 IP 주소와 포트 번호를 메모리의 작은 제어영역(control block)에 기록해 놓는다.
* 이 정보는 같은 주소와 포트 번호를 사용하는 새로운 TCP 커넥션이 일정 시간 동안에는 생성되지 않게 하기 위한 것
* 보통 세그먼트의 최대 생명주기에 두 배 정도(‘2MSL’ 이라하며 2분 정도)의 시간동안 유지
* 이는 이전 커넥션과 관련된 패킷이 같은 주소, 포트의 커넥션에 삽입되는 문제를 방지
* 특정 커넥션이 생성되고 닫힌 다음, 그와 같은 IP주소, 포트를 가지는 커넥션이 2분 이내에 또 생성되는 것을 막아준다.

현대는 라우터가 빨라져서 커넥션이 닫힌 후에 중복되는 패킷이 생기는 경우는 거의 없다.
* 2MSL을 짧게 수정하는 운영체제도 있지만, 조심해야 한다.
* 이전 커넥션 패킷이 새로운 커넥션에 삽입되면, 패킷은 중복되고 TCP 데이터는 충돌되기 때문

일반적으로는 2MSL의 커넥션 종료 지연이 문제가 되지는 않지만, 성능시험을 하는 상황에서는 문제가 될 수 있다.
* 성능 측정 대상 서버는 클라가 접속할 수 있는 IP 주소 개수를 제한한다.
* 서버에 접속하여 부하를 발생시킬 컴퓨터의 수는 적다.
* 일반적으로 서버는 HTTP의 기본 TCP 포트인 80번을 사용하기 때문에 이런 상황에서는 가능한 연결의 조합이 제한된다.
    * TIME_WAIT로 인해서 순간순간 포트를 재활용하는 것이 불가능해진다.

각각 한 개의 클라와 서버가 있을 때 발신지 IP, 목적지 IP, 목적지 포트는 고정이고 발신지 포트만 변경할 수 있다고 하자
* 서버에 접속할 때마다 유일한 커넥션을 생성하기 위해 새로운 발신지 포트를 쓴다.
    * 발신지 포트는 60000개로 가정하고 2MSL초 동안 커넥션이 재사용 될 수 없다.
    * 초당 500개(60000/120)로 커넥션이 제한된다.
* 초당 500개 이상 트랜잭션을 처리할 만큼 빠르지 않다면 TIME_WAIT 고갈은 일어나지 않는다.
* 이 문제를 해결하기 위해 장비를 더 사용하거나, 가상 IP를 쓸 수 있다.

### HTTP 커넥션 관리

#### 흔히 잘못 이해하는 Connection 헤더
HTTP 메시지는 클라에서 서버(혹은 리버스 서버)까지 중개 서버들을 하나하나 거치면서 전달된다.

어떤 경우에는 두 개의 인접한 HTTP 애플리케이션이 현재 맺고 있는 커넥션에만 적용될 옵션을 지정해야 할 때가 있다.
* HTTP Connection 헤더 필드는 커넥션 토큰을 쉼표로 구분
* Connection 헤더는 다음 세 가지 종류의 토큰이 전달될 수 있다.
    * HTTP 헤더 필드 명은, 이 커넥션에만 해당되는 헤더들을 나열
    * 임시적인 토큰 값은, 커넥션에 대한 비표준 옵션을 의미
    * close 값은, 커넥션이 작업이 완료되면 종료되어야 함을 의미

커넥션 토큰이 HTTP 헤더 필드 명을 가지고 있으면, 해당 필드들은 현재 커넥션만을 위한 정보이므로 다른 커넥션에 전달하면 안된다.
* Connection 헤더에 있는 모든 필드는 다른 곳으로 전달하는 시점에 삭제되어야 한다.
* Connection 헤더에는 홉별 헤더 명을 기술하는데, 이것을 ‘헤더 보호하기’라 한다.
    * Connection 헤더에 명시된 헤더들이 전달되는 것을 방지하기 때문

HTTP 애플리케이션이 Connection 헤더와 함꼐 메시지를 받으면, 모든 옵션을 적용하고 다음 홉에 전달하기 전에 Connection 헤더에 있는 모든 헤더를 삭제한다.
* Connection 헤더에 기술되어 있지는 않더라도, 홉별 헤더인 것들도 있다.

```
HTTP/1.1 200 OK
Cache-control: max-age=3600
Connection: meter, close, bill-my-credit-card
Meter: max-uses=3, max-refuses=6, dont-report
```

#### 순차적인 트랜잭션 처리에 의한 지연
예를 들어 3개의 이미지가 있는 웹페이지는 네 개의 트랜잭션을 만들어야 한다.
* 하나의 HTML 트랜잭션
* 세 개의 이미지 트랜잭션
* 각 트랜잭션 커넥션을 맺는데 발생하는 지연과 함께 느린 시작 지연이 발생한다.

순차적인 처리로 인해 물리적인 지연 뿐 아니라, 하나의 이미지를 내려받는 도중 나머지 이미지 공간에 아무런 변화가 없어서 느끼는 심리적 지연도 있다.
* 사용자는 여러 개의 이미지가 동시에 로드되는 걸 더 느리더라도 선호한다.

### 병렬 커넥션
하나씩 커넥션을 맺어서 내려받는 식으로 웹페이지를 보여주는 방식은 너무 느리다.
* 클라가 여러 개의 커넥션을 병렬로 맺음으로써 트랜잭션을 병렬로 처리할수 있다.

#### 병렬 커넥션은 페이지를 더 빠르게 내려받는다.
단일 커넥션의 대역폭 제한과 커넥션이 동작하지 않고 있는 시간을 활용하면, 객체가 여러 개 있는 웹페이지를 더 빠르게 내려 받을 수 있다.

#### 병렬 커넥션이 항상 더 빠르지는 않다.
클라의 네트워크 대역폭이 좁을 때는 대부분 시간을 데이터를 전송하는 데만 쓸 것이다.
* 병렬로 내려받는 경우, 제한된 대역폭 내에서 각 객체를 전송받는 것은 느리기 때문에 성능상의 장점은 거의 없어진다.
* 다수의 커넥션은 메모리를 많이 소모하고 자체적인 성능 문제를 발생시킨다.
* 클라가 수백개의 커넥션을 열 수도 있지만 서버는 여러 사용자의 요청도 함께 처리해야 하기 떄문에 수백개의 커넥션을 허용하는 건 드물다.
* 브라우저는 실제로 병렬 커넥션을 사용하긴 하지만 적은 수(대부분 4개, 최신은 6~8개)의 병렬 커넥션을 허용한다.
* 과도한 수가 맺어지면 임의로 끊어버린다.

#### 병렬 커넥션은 더 빠르게 ‘느껴질 수’ 있다.
항상 더 빠르게 로드하지는 않는다.
* 화면에 여러 개의 객체가 동시에 내려받고 있어서 빠르게 내려받는 것처럼 느낀다.

### 지속 커넥션
웹 클라는 보통 같은 사이트에 여러 개의 커넥션을 맺는다.
* HTTP 요청을 하기 시작한 애플리케이션은 웹페이지 내의 이미지 등을 가져오기 위해 그 서버에 또 요청한다.
* 이 속성을 사이트 지역성(site locality)라고 부른다.

HTTP/1.1을 지원하는 기기는 처리가 완료되도 TCP 커넥션을 유지하는데 이걸 지속 커넥션이라 한다.
* 앞으로 있을 요청에 재사용 하기 위해
* 지속 커넥션을 재사용함으로써, 커넥션을 맺기 위한 준비작업에 따르는 시간을 절약할 수 있다.
* 게다가 느린 시작으로 인한 지연을 피함으로써 더 빠르게 데이터를 전송할 수 있다.

#### 지속 커넥션 vs 병렬 커넥션
병렬 커넥션은 여러 객체가 있는 페이지를 더 빠르게 전송하지만 몇 가지 단점이 있다.
* 각 트랜잭션마다 새로운 커넥션을 맺고 끊기 때문에 시간과 대역폭이 소요된다.
* 각각의 새로운 커넥션은 TCP 느린 시작 때문에 성능이 떨어진다.
* 실제로 연결할 수 있는 병렬 커넥션의 수에는 제한이 있다.

지속 커넥션은 병렬 커넥션에 비해 몇 가지 장점이 았다.
* 커넥션을 맺기 위한 사전 작업과 지연을 줄여준다.
* 튜닝된 커넥션을 유지한다.
* 커넥션의 수를 줄여준다.

지속 커넥션을 잘못 관리할 경우, 계속 연결된 상태로 있는 수많은 커넥션이 쌓이게 된다.
* 클라, 서버의 불필요한 리소스 소모를 발생시킨다.

지속 커넥션은 병렬 커넥션과 함께 사용될 때 가장 효과적이다.
* 오늘날은 적은 수의 병렬 커넥션만을 맺고 그것을 유지
* 두 가지 타입이 있다.
    * HTTP/1.0+에는 ‘keep-alive’ 커넥션
    * HTTP/1.1에는 ‘지속’ 커넥션

#### HTTP/1.0+의 Keep Alive 커넥션
초기 HTTP/1.0의 지속 커넥션은 상호 운용과 관련된 설계에 문제가 있었지만, 아직 많은 클라와 서버는 이 초기 keep-alive 커넥션을 사용하고 있다.
* 설계상의 문제는 HTTP/1.1에서 수정되었다.

keep-alive 커넥션의 장점은 커넥션을 맺고 끊는 데 필요한 작업이 없어서 시간이 단축된다.
* 또 느린 시작이 일어나지 않아 요청 및 응답 시간이 줄어든다.

#### Keep-Alive 동작
keep-alive는 사용하지 않기로 결정되어 HTTP/1.1 명세에서 빠졌다.
* 하지만 아직도 keep-alive 핸드셰이크가 널리 사용하고 있기 떄문에, 그것을 처리할 수 있게 개발해야 한다.

HTTP/1.0 keep-alive 커넥션을 유지하기 위해 요청에 Connection:Keep-Alive 헤더를 포함한다.
* 서버는 그다음 요청도 이 커넥션으로 받기를 원하면 Connection:Keep-Alive 헤더를 포함한다.
* 응답에 해당 헤더가 없으면 서버가 지원하지 않는다고 추정하고 커넥션을 끊는다.

#### Keep-Alive 옵션
Keep-Alive 헤더는 커넥션을 유지하기를 바라는 요청일 뿐이다.
* 그것을 따를 필요는 없고, 언제든지 끊을 수도 커넥션에서 처리되는 트랜잭션 수를 제한할 수 있다.
* Keep-Alive헤더는 Connection: Keep-Alive 헤더가 있을 때만 사용 가능

다음 예는 5개의 추가 트랜잭션이 처리될 동안 커넥션을 유지하거나, 2분동안 커넥션을 유지하라는 내용의 헤더
```
Connection: Keep-Alive
Keep-Alive: max=5, tiemout=120
```

#### Keep-Alive 커넥션 제한과 규칙
keep-alive 커넥션에 대한 몇 가지 제한과 사용 방법에대한 상세 내용
* HTTP1.0에서 기본적으로 사용되지는 않는다.
    * 클라는 사용하기 위해 Connection:Keep-Alive 헤더를 보내야 한다.
* 커넥션을 유지하려면 모든 메시지가 해당 헤더를 포함해야 한다.
* 응답 헤더에 없으면 서버가 응답 후에 커넥션을 끊을 거라는 걸 알 수 있다.
* 커넥션이 끊어지기 전에 엔티티 본문의 길이를 알 수 있어야 커넥션을 유지할 수 있다.
    * 잘못된 Content-Length 값을 보내면 메시지의 끝과 시작점을 정확히 알 수 없다.
* 프락시와 게이트웨이는 Connection 헤더의 규칙을 철저히 지켜야 한다.
    * 프락시와 게이트웨이는 메시지를 전달하거나 캐시에 넣기 전에 Connection 헤더에 명시된 모든 헤더 필드와 Connection 헤더를 제거해야 한다.
* 정석대로라면, Connection 헤더를 인식하지 못하는 프락시 서버와는 맺어지면 안된다.
* 기술적으로 HTTP/1.0을 따르는 기기로부터 받는 모든 Connection 헤더 필드(Connection:Keep-Alive)는 무시해야 한다.
    * 오래된 프락시 서버로부터 실수로 전달될 수 있기 떄문
* 클라는, 응답 전체를 모두 받기 전에 커넥션이 끊어졌을 경우, 별다른 문제가 없으면 요청을 다시 보낼 수 있게 준비되어 있어야 한다.

#### Keep-Alive와 멍청한(dumb) 프락시

Connection 헤더의 무조건 전달
프락시에 의해 문제가 시작된다. 프락시는 Connection 헤더를 이해하지 못해서 해당 헤더들을 삭제하지 않고 요청 그대로를 다음 프락시로 전달한다.
* 클라는 프락시에 Connection: Keep-Alive 헤더와 함께 메시지를 보낸다.
    * 클라는 커넥션을 유지하자는 요청이 받아들여졌는지 확인하기 위해 응답을 기다린다.
* 멍청한 프락시는 해당 헤더를 이해하지 못하고 다음 서버에 메시지를 그대로 전달한다.
    * Connection 헤더는 홉별 헤더이기 떄문에 전달되서는 안되는 메시지이다.
* 서버가 프락시로부터 해당 헤더를 받으면, 커넥션을 유지하자고 요청하는 것으로 판단해 해당 헤더를 포함하여 응답한다.
    * 웹 서버는 프락시와 keep-alive 커넥션이 맺어져 있는 상태로 통신을 하는 것으로 판단한다.
* 프락시는 서버로 받은 해당 헤더를 클라에게 그대로 전달한다.
    * 클라는 프락시가 커넥션을 유지하는 것에 동의했다고 추정한다.
    * 정작 프락시는 keep-alive를 전혀 이해하지 못함
* 프락시는 모든 데이터를 클라에게 전달하고 나서 서버가 커넥션을 끊기를 기다린다.
    * 서버는 커넥션을 유지하고 있기 때문에 프락시는 끊어지기를 계속 기다린다.
* 클라가 응답 메시지를 받으면, 커넥션이 유지되고 있는 프락시에 다음 요청을 보낸다.
    * 프락시는 같은 커넥션상에서 다른 요청이 오는 것을 예상하지 못하기 때문에 무시되고 브라우저는 응답없이 로드 중이라는 표시만 나온다.
* 이런 잘못된 통신 때문에, 브라우저는 자신이나 서버가 타임아웃이 나서 커넥션이 끊길 때까지 기다린다.
    * 이 밖에도, 무조건 전달(blind relay)과 핸드셰이크의 전달(forwarded handshaking)로 인해 발생되는 문제들이 많다.

프락시별 홉별 헤더
* 이런 종류의 잘못된 통신을 피하려면, 프락시는 Connection 헤더와 Connection 헤더에 명시된 헤더들은 절대 전달하면 안된다.

#### Proxy-Connection 살펴보기
넷스케이프의 브라우저 및 프락시 개발자들은 모든 웹 애플리케이션이 HTTP 최신 버전을 지원하지 않아도, 모든 헤더를 무조건 전달하는 문제를 해결할 수 있는 기발한 차선책을 개발
* Proxy-Connection이라는 헤더를 사용
* 프락시를 별도로 설정할 수 있는 현대의 브라우저들에서 지원하고 있으며, 많은 프락시들도 이것을 인식
* 비표준 Proxy-Connection 확장 헤더이기 때문에 무조건 전달하더라도 웹 서버는 그것을 무시하기 때문에 문제가 생기지 않는다.
* 영리한 프락시라면, Proxy-Connection 헤더를 Connection 헤더로 바꿈으로써 원하던 효과를 얻는다.

이 방식은 클라와 서버 사이에 한 개의 프락시만 있는 경우에서만 동작한다.
* 멍청한 프락시의 양옆에 영리한 프락시가 있다면 잘못된 헤더를 만들어내는 문제가 다시 발생

#### HTTP/1.1의 지속 커넥션
HTTP/1.1에서는 keep-alive 커넥션을 지원하지 않는 대신, 설계가 더 개선된 지속 커넥션을 지원
* keep-alive와는 달리 1.1의 지속 커넥션은 기본적으로 활성화
* 별도 설정하지 않는 한, 모든 커넥션을 지속 커넥션으로 취급
* 트랜잭션이 끝난 다음에 커넥션을 끊으려면 Connection: close 헤더를 명시
* keep-alive가 선택사항이 아닐 뿐더라 지원 자체를 하지 않는다는 점에서 이전 HTTP 프로토콜과 크게 다르다.
* Connection: close를 보내지 않는다 해서 영원히 유지하겠다는 건 아니고 클라와 서버는 언제든지 커넥션을 끊을 수 있다.

#### 지속 커넥션의 제한과 규칙
* 클라가 요청에 Connection: close 헤더를 포함해 보냈으면, 클라는 그 커넥션으로 추가적인 요청을 보낼 수 없다.
* 클라가 해당 커넥션으로 추가적인 요청을 보내지 않을 거라면, 마지막 요청에 Connection: close 헤더를 보내야 한다.
* 모든 메시지가 자신의 길이 정보를 정확히 가지고 있을 때 커넥션을 지속시킬 수 있다.
    * 정확한 Content-Length 값을 가지거나 청크 전송 인코딩으로 인코드 되어 있어야 한다.
* 1.1 프락시는 클라와 서버 각각에 대해 별도의 지속 커넥션을 맺고 관리해야 한다.
* 1.1 프락시 서버는 클라가 커넥션 관련 기능에 대한 클라의 지원 범위를 알고 있지 않은 한 지속 커넥션을 맺으면 안 된다.
    * 오래된 프락시가 Connection 헤더를 전달하는 문제가 발생할 수 있기 때문
    * 이것은 쉽지 않으며, 많은 벤더가 이 규칙을 지키지 않는다.
* 서버는 메시지를 전송하는 중간에 끊지 않고, 끊기기 전에 적어도 한 개의 요청에 대해 응답할 것이긴 하지만, 1.1 기기는 헤더의 값과는 상관없이 언제든지 끊을 수 있다.
* 1.1 애플리케이션은 중간에 끊어지는 커넥션을 복구할 수 있어야만 한다.
    * 클라는 다시 보내도 문제가 없는 요청이라면 가능한 한 다시 보내야 한다.
* 클라는 전체 응답을 받기 전에 커넥션이 끊어지면, 요청을 반복해서 보내도 문제가 없는 경우 요청을 다시 보낼 준비가 되어 있어야 한다.
* 하나의 사용자 클라는 서버의 과부하를 방지하기 위해서, 넉넉잡아 두 개의 지속 커넥션만을 유지해야 한다.
    * N명의 사용자가 서버로 접근하려한다면, 프락시는 서버나 상위 프락시에 넉넉잡아 약 2N개의 커넥션을 유지해야 한다.

### 파이프라인 커넥션
HTTP/1.1은 지속 커넥션을 통해서 파이프라이닝할 수 있다.
* 이는 keep-alive 커넥션의 성능을 더 높여준다.
* 여러 개의 요청은 응답이 도착하기 전까지 큐에 쌓인다. 첫번째 요청이 서버로 전달되면, 거기에 이어 두, 세 번쨰 요청이 전달될 수 있다.

파이프라인에는 여러 가지 제약 사항이 있다.
* 클라는 커넥션이 지속 커넥션인지 확인하기 전까지는 파이프라인을 이어서는 안된다.
* 응답은 요청 순서와 같게 와야 한다.
    * HTTP 메시지는 순번이 매겨져 있지 않아서 응답이 순서 없이 오면 순서에 맞게 정렬시킬 방법이 없다.
* 클라는 커넥션이 언제 끊어지더라도, 완료되지 않은 요청이 파이프라인에 있으면 언제든 다시 요청을 보낼 준비가 되어 있어야 한다.
* POST 요청같이 비멱등 요청은 파이프라인을 통해서 보내면 안 된다.
    * 에러가 발생하면 파이프라인을 통한 요청 중에 어떤 것들이 서버에서 처리되었는지 클라가 알 방법이 없다.

### 커넥션 끊기에 대한 미스터리
커넥션 관리에는 명확한 기준이 없다.
* 특히 언제 커넥션을 끊는가

#### ‘마음대로’ 커넥션 끊기
보통 커넥션은 메시지를 다 보낸 다음에 끊지만, 에러가 있는 상황에서는 헤더의 중간이나 다른 엉뚱한 곳에서 끊길 수 있다.
* 서버가 유휴상태에 있는 커넥션을 끊는 시점에, 클라가 데이터를 전송하게 되면 문제가 생긴다.

#### Content-Length와 Truncation
각 응답은 본문의 정확한 크기 값을 가지는 Content-Length 헤더를 가지고 있어야 한다.
* 일부 오래된 서버는 자신이 커넥션을 끊으면 데이터 전송이 끝났음을 의미하는 형태로 개발되어 있어서, 해당 헤더를 생략하거나 잘못된 길이 정보로 응답하는 경우도 있다.
* 클라나 프락시가 커넥션이 끊어졌다는 응답을 받은 후, 실제 전달된 엔티티의 길이와 Content-Length의 값이 일치하지 않거나 존재하지 않으면 정확한 길이를 서버에게 물어봐야 한다.

#### 커넥션 끊기의 허용, 재시도, 멱등성
커넥션은 심지어 에러가 없더라도 언제든지 끊을 수 있다.
* 예상치 못하게 커넥션이 끊어졌을 때 적절히 대응할 수 있는 준비가 되어있어야 한다.
* 전송 도중 끊기게 되면, 클라는 재시도 했을때 문제가 없다면 재시도 해야 한다.

파이프라인 커넥션에서는 어려워진다.
* 클라는 여러 요청을 큐에 쌓을 수 있지만, 서버는 아직 처리되지않은 요청들을 남겨둔 채로 커넥션을 끊어버릴 수 있다.
* 클라는 이 상황에서 얼마나 처리되었는지 전혀 알 수 없다.
* 멱등 메서드는 상관없지만 비멱등 요청이 반복될 경우 문제가 발생
    * 멱등 메서드
        * GET
        * HEAD
        * PUT
        * DELETE
        * TRACE
        * OPTIONS
* 비멱등 요청을 보내야 한다면, 이전 요청에 대한 응답을 받을 때까지 기다려야 한다.
* 비멱등 메서드는 자동으로 재시도하면 안 된다.
    * 대부분 브라우저는 캐시된 POST 요청 페이지를 다시 로드하려고 할 때, 다시 보내기를 원하는지 묻는 대화상자를 보여준다.

#### 우아한 커넥션 끊기
TCP 커넥션의 양쪽에는 데이터를 읽거나 쓰기 위한 입력 큐와 출력 큐가 있다.
* 한쪽 출력 큐에 있는 데이터는 다른 쪽의 입력 큐에 보내질 것이다.

전체 끊기와 절반 끊기

애플리케이션은 TCP 입력, 출력 채널 중 한 개만 끊거나 둘 다 끊을 수 있다.
* close()를 호출하면 입력, 출력 채널의 커넥션을 모두 끊는다.
    * 이를 전체 끊기
* 입력 채널이나 출력 채널 중에 하나를 개별 끊으려면 shotdown()을 호출
    * 이를 절반 끊기
    * 출력 절반 끊기가 우아한 커넥션 끊기

TCP 끊기와 리셋 에러

단순한 HTTP 애플리케이션은 전체 끊기만을 사용할 수 있다.
* 각기 다른 HTTP 클라, 서버, 프락시와 통신할 때, 그리고 파이프라인 지속 커넥션을 사용할 때 예상치 못한 쓰기 에러를 방지하기 위해 ‘절반 끊기’를 사용해야 한다.
* 보통은 출력 채널을 끊는 것이 안전하다.
* 클라는 더는 데이터를 보내지 않을 것임을 확신할 수 없는 이상, 커넥션의 입력 채널을 끊는 것은 위험하다.
* 만약 이미 끊긴 입력 채널에 데이터를 전송하면, 서버의 운영체제는 TCP ‘connection reset by peer’ 메시지를 클라에 보낸다.
    * 대부분 운영체제는 이것은 심각한 에러로 취급하여 버퍼에 저장된, 아직 읽히지 않은 데이터들을 모두 삭제한다.
    * 이 상황은 파이프라인 커넥션에서는 더 악화된다.
* 10개의 요청을 파이프라인 지속 커넥션으로 전송했고, 서버는 커넥션을 끊으면 11번 째 요청을 보낼 때 ‘connection reset by peer’ 메시지를 받아서 입력 버퍼에 있는 데이터를 지운다.

우아하게 커넥션 끊기

HTTP 명세에서는 클라나 서버가 예기치 않게 커넥션을 끊어야 한다면, “우아하게 커넥션을 끊어야 한다”라고 하지만, 정작 그 방법은 설명하지 않고 있다.
* 일반적인 우아한 커넥션 끊기를 구현하는 것은 애플리케이션 자신의 출력 채널을 먼저 끊고 다른 쪽에 있는 기기의 출력 채널이 끊기는 것을 기다리는 것
    * 양쪽에서 더는 데이터를 전송하지 않을 것이라고 알려주면, 커넥션은 리셋의 위험 없이 온전히 종료
* 상대방이 절반 끊기를 구현했다는 보장도 없고 절반 끊기를 했는지 검사해준다는 보장이 없다.
    * 따라서 커넥션을 우아하게 끊고자 하는 애플리케이션은 출력 채널에 절반 끊기를 하고 난 후에도 데이터나 스트림의 끝을 식별하기 위해 입력 채널에 대해 상태 검사를 주기적으로 해야 한다.
        * 만약 입력 채널이 특정 타임아웃 시간 내에 끊어지지 않으면, 애플리케이션은 리소스를 보호하기 위해 커넥션을 강제로 끊을 수 있다.
