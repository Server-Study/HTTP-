# 캐시

웹 캐시는 자주 쓰이는 문서의 사본을 자동으로 보관하는 HTTP 장치다. 캐시는 여러 가지 혜택을 준다.

### 불필요한 데이터 전송
복수의 클라가 자주 쓰이는 원 서버 페이지에 접근할 때, 클라에게 각각 한 번씩 전송하게 된다.
* 불필요한 데이터 전송은 값비싼 네트워크 대역폭을 잡아먹고, 전송을 느리게 만들고, 웹 서버에 부하를 준다.
* 첫 번째 응답은 캐시에 보관되고 뒤이은 요청에 대한 응답으로 사용

### 대역폭 병목
캐시는 또한 네트워크 병목을 줄여준다.
* 믾은 네트워크가 원격 서버보다 로컬 네트워크 클라에 더 넓은 대역폭을 제공
* 클라가 빠른 LAN에 있는 캐시로부터 사본을 가져온다면, 캐싱은 성능을 대폭 개선한다.

### 갑작스런 요청 쇄도(Flush Crowds)
캐싱은 갑작스런 요청 쇄도에 대처하기 위해 특히 중요하다.
* 갑작스런 사건에 인해 많은 사람이 거의 동시에 웹 문서에 접근할 때 발생하는 불필요한 트래픽 급증은 네트워크와 웹 서버의 심각한 장애를 야기시킨다.

### 거리로 인한 지연
대역폭이 문제가 되지 않더라도, 거리가 문제 될 수 있다.
* 모든 네트워크 라우터는 제각각 인터넷 트래픽을 지연시킨다.
* 라우터가 많지 않더라도, 빛의 속도 그 자체가 유의미한 지연을 유발한다.
* 보통 수준으로 복잡한 웹페이지들은 빛의 속도로 인한 지연이 수 초에 달할 수도 있다.
* 기계실 근처에 캐시를 설치해서 문서가 전송되는 거리를 수천 킬로미터에서 수십 미터로 줄일 수 있다.

### 적중과 부적중
캐시는 유용하다. 그러나 세상 모든 문서의 사본을 저장을 하지는 않는다.(불가능)
* 캐시에 요청이 도착했을 때 사본이 있다면 캐시 적중(cache-hit)
* 대응하는 사본이 없다면 원 서버로 전달되는걸 캐시 부적중(cache miss)

#### 재검사(Revalidation)
원 서버 콘텐츠는 변경될 수 있기 때문에, 캐시는 반드시 갖고 있는 사본이 여전히 최신인지 서버를 통해 때때로 점검해야 한다.
* 캐시된 사본의 재검사가 필요할 때, 원 서버에 작은 재검사 요청을 보낸다.
    * 콘텐츠가 변경되지 않았다면, 서버는 아주 작은 304 Not Modified 응답을 보낸다.
        * 이를 재검사 적중 혹은 느린 적중이라 한다.
* HTTP는 캐시된 객체를 재확인하기 위해 몇 가지 도구를 제공한다. 

가장 많이 쓰이는 것은 If-Modified-Since 헤더.
* 서버에게 보내는 GET 요청에 이 헤더를 추가하면 캐시된 시간 이후 변경된 경우에만 사본을 보내달라는 의미
* 세 가지 상황이 일어날 수 있다.
    * 서버 콘텐츠가 변경되지 않은 경우
    * 서버 콘텐츠가 변경된 경우
    * 객체가 삭제된 경우

재검사 적중
* 서버 객체가 변경되지 않았다면, 서버는 304 Not Modified 응답을 보낸다.

재검사 부적중
* 서버 객체가 캐시된 사본과 다르다면, 서버는 콘텐츠 전체와 함께 평범한 200 OK 응답을 클라에게 보낸다.

객체 삭제
* 서버 객체가 삭제되었다면, 404 Not Found 응답을 돌려보내며, 캐시는 사본을 삭제한다.

#### 적중률
캐시가 요청을 처리하는 비율을 캐시 적중률(캐시 적중비), 혹은 문서 적중률(문서 적중비)라고 부르기도 한다.
* 실제 적중률은 다음과 같은 내용에 달려있다.
    * 캐시가 얼마나 큰지
    * 캐시 사용자들의 관심사가 얼마나 비슷한지
    * 캐시된 데이터가 얼마나 자주 변경되거나 개인화되는지
    * 캐시가 어떻게 설정되어 있는지
* 적중률은 예측하기 어렵지만 오늘날 40%면 웹 캐시로 괜찮다.

### 바이트 적중률
문서들이 모두 같은 크기인 것은 아니기 때문에 문서 적중률은 모든 것을 말해 주지 않는다.
* 몇몇 큰 객체는 덜 접근되지만 전체 트래픽에 더 크게 기여할 수 도 있다.

바이트 단위 적중률은 캐시를 통해 제공된 모든 바이트의 비율을 표현한다.
* 이 측정값은 트래픽이 절감된 정도를 포착해낸다.
* 문서 적중률, 바이트 단위 적중률 둘 다 캐시 성능에 대한 유용한 지표
* 문서 적중률을 개선하면 전체 대기시간이 줄어든다.
    * TCP 커넥션을 맺는것과 같은 고정된 시간이 줄어든다.
* 바이트 단위 적중률을 개선하면 대역폭 절약을 최적화한다.

#### 적중과 부적중의 구별
HTTP는 클라에게 응답이 캐시 적중인지 원 서버 접근인지 말해줄수 있는 방법을 제공하지 않는다.
* 두 경우 모두 본문을 갖고 있음을 의미하는 200 OK 응답 코드를 내려준다.
* 응답이 캐시에서 왔는지 알아내는 한 가지 방법은 Date 헤더를 이용
    * 응답의 Date 헤더 값을 현재 시각과 비교하여, 응답의 생성일이 더 오래되었다면 캐시된 것임을 알 수 있다.
* 클라가 캐시된 응답을 감지하는 또 다른 방법은, 응답이 얼마나 오래되었는지 말해주는 Age 헤더를 이용

### 캐시 토폴로지

#### 개인 전용 캐시
개인 전용 캐시는 많은 에너지나 저장 공간을 필요로 하지 않으므로, 작고 저렴하다.
* 웹 브라우저는 개인 전용 캐시를 내장

#### 공용 프락시 캐시
프락시 캐시는 로컬 캐시에서 문서를 제공하거나, 혹은 사용자의 입장에서 서버에 접근한다.
* 공용 캐시에는 여러 사용자가 접근하기 때문에, 불필요한 트래픽을 줄일 수 있는 더 많은 기회가 있다.

#### 프락시 캐시 계층들
작은 캐시에서 캐시 부적중이 발생했을 때 더 큰 부모 캐시가 그 ‘걸러 남겨진’ 트래픽을 처리하도록 하는 계층을 만드는 방식이 합리적인 경우가 많다.
* 클라 주위에는 작고 저렴한 캐시
* 그 캐시 계층 상단에는 많은 사용자들에 의해 공유되는 더 크고 강력한 캐시

#### 캐시망, 콘텐츠, 라우팅, 피어링
몇몇 네트워크 아키텍처는 단순한 캐시 계층 대신 복잡한 캐시망을 만든다.
* 요청이 어디로 갈 것인지에 대해 동적으로 결정한다.
    * URL에 근거하여, 부모 캐시와 원 서버 중 하나를 선택
    * URL에 근거하여, 특정 부모 캐시를 선택
    * 부모 캐시 가기 전에, 로컬 캐시를 찾는다.
    * 다른 캐시들이 그들의 캐시된 콘텐츠에 부분적으로 허용하되, 그들의 캐시를 통한 인터넷 트랜짓은 허용하지 않는다.

### 캐시 처리 단계
오늘날 상용 프락시는 꽤 복잡하다. 매우 고성능이면서 HTTP와 그 외 다른 고급 기능을 지원하도록 만들어졌다.
1. 요청 받기
2. 파싱
3. 검색
4. 신선도 검사
5. 응답 생성
6. 발송
7. 로깅

#### 요청 받기
네트워크 커넥션에서의 활동을 감지하고, 들어오는 데이터를 읽어들인다.

#### 파싱
요청 메시지를 여러 부분으로 파싱하여 헤더 부분을 조작하기 쉬운 자료 구조에 담는다.

#### 검색
캐시는 URL을 알아내고 그에 해당하는 로컬 사본이 있는지 검색
* 전문적인 수준의 캐시는 객체를 로컬 캐시에서 가져올 수 있는지 판단하기 위해 빠른 알고리즘을 사용

#### 신선도 검사
HTTP는 캐시가 일정 기간 동안 서버 문서의 사본을 보유할 수 있도록 해준다.
* 이 기간 동안을 ‘신선’한 것으로 간주
* 신선도 한계를 넘었다면 그 문서를 제공하기 전에 변경 사항에 대해 원 서버와 재검사를 해야 한다.

#### 응답 생성
캐시된 응답을 원 서버에 온 것처럼 보이게 하고 싶기 때문에, 캐시는 캐시된 서버 응답 헤더를 토대로 응답 헤더를 생성
* 이 기저 해더들은 캐시에 의해 수정되고 늘어난다.
* 캐시는 캐시 신선도 정보를 삽입(Cache-Control Age, Expires 헤더), 또 종종 Via 헤더를 포함
* Date 헤더는 그 객체가 원 서버에서 최초로 생겨난 일시를 표현하는 것이기 때문에 Date 헤더를 조정해서는 안된다.

#### 전송
응답 헤더가 준비되면, 클라에게 돌려준다.
* 프락시 캐시는 클라와 커넥션을 유지할 필요가 있다.

#### 로깅
대부분의 캐시는 로그 파일과 캐시 사용에 대한 통계를 유지
* 트랜잭션이 완료된 후, 캐시는 통계 캐시 적중과 부적중 횟수에 대한 통계를 갱신하고 로그 파일에 요청 종류, URL 그리고 무엇이 일어났는지 알려주는 항목을 추가

### 사본을 신선하게 유지하기
캐시된 사본 모두가 서버의 문서와 항상 일치하는 것은 아니다.
* 캐시된 데이터는 서버의 데이터와 일치하도록 관리되어야 한다.

#### 문서 만료
HTTP는 Cache-Control과 Expires라는 특별한 헤더들을 이용해서 원 서버가 각 문서에 유효기간을 붙일 수 있게 해준다.
* 캐시 문서가 만료되면, 서버와 문서의 변경이 있는지 검사해야 하며, 그렇다면 신선한 사본을 얻어 와야 한다(새 유효기간과 함께)

#### 유효기간과 나이
서버는 응답 본문과 함께 하는, HTTP/1.0+ Expires나 HTTP/1.1 Cache-Control: max-age 응답 헤더를 이용해 유효기간을 명시
* Cache-Control: max-age=484200
* Expires: Fri, 05 Jul 2002,, 05:00:00 GMT

#### 서버 재검사
캐시 문서가 만료되었다는 것은, 실제로 다르다는 것을 의미하지 않으며, 다만 이제 검사할 시간이 되었음을 뜻한다.
* 재검사 결과 콘텐츠가 변경되었다면, 새로운 사본을 가져와 오래된 데이터 대신 저장한 뒤 클라에게 보내준다.
* 변경되지 않았다면, 캐시는 새 만료일을 포함한 새 헤더들만 가져와서 캐시 안의 헤더들을 갱신한다.

#### 조건부 메서드와의 재검사
HTTP의 조건부 메서드는 재검사를 효율적으로 만들어준다.
* '조건부 GET'이라는 요청은 서버가 갖고 있는 문서가 캐시가 갖고 있는 것과 다른 경우에만 객체 본문을 보내달라고 하는 것
    * 신선도 검사와 객체를 받아 오는 것을 하나의 조건부 GET으로 결합
* 요청 메시지에 특별한 조건부 헤더를 추가함으로써 시작된다.

#### If-Modified-Since: 날짜 재검사
If-Modified-Since 재검사 요청은 흔히 ‘IMS’라고 불린다. 서버에게 리소스가 특정 날짜 이후 변경된 경우에만 요청한 본문을 보내달라고한다.
* 주어진 날짜 이후 변경되었다면, 조건은 참이고 GET요청은 성공한다. 새 문서가, 새로운 만료 날짜와 그 외 다른 정보들이 담긴 헤더들과 함께 캐시에게 반환
* 조건이 거짓이면, 본문은 보내지 않고 304 Not Modified 응답 메시지를 클라에게 돌려준다.

If-Modified-Since 헤더는 서버 응답 헤더의 Last-Modified 헤더와 함께 동작한다.
* 원 서버는 제공하는 문서에 최근 변경 일시를 붙인다.
* 캐시카 캐시된 문서를 재검사 하려고 할 때, 캐시된 사본이 마지막으로 수정된 날짜가 담긴 If-Modified-Since 헤더를 포함
* If-Modified-Since: <캐시된 마지막 수정일>

#### If-None-Match: 엔티티 태그 재검사
최근 변경 일시 재검사가 적절히 행해지기 어려운 상황이 몇 가지 있다.
* 어떤 문서는 일정 시간 간격으로 다시 쓰여지지만 실제로는 같은 데이터를 포함
    * 내용에는 아무런 변화가 없더라도 변경시각은 바뀔 수 있다.
* 어떤 문서들의 변경은 전 세계의 캐시들이 그 데이터를 다시 읽어들이기엔 사소한 것일 수도 있다.
    * 철자나 주석의 변경
* 어떤 서버들은 그들이 갖고 있는 페이지에 대한 최근 변경 일시를 정확하게 판별할 수 없다.
* 1초보다 작은 간격으로 갱신되는 문서를 제공하는 서버들에게는, 변경일에 대한 1초의 정밀도는 충분하지 않을 수 있다.

퍼블리셔가 문서를 변경했을 때, 문서의 엔티티 태그를 새로운 버전으로 표현할 수 있다.
* If-None-Match: “v2.6"
* 캐시가 객체에 대한 여러 개의 사본을 갖고 있는 경우, If-None-Match 헤더에 여러 개의 엔티티 태그를 포함시킬 수 있다.
* If-None-Match: “v2.4”,”v2.5”,”v2.6"

#### 약한 검사기와 강한 검사기
서버는 때때로 모든 캐시된 사본을 무효화시키지 않고 살짝 고칠 수 있도록 허용하고 싶은 경우가 있다.
* HTTP/1.1은, 조금 변경되었더라도 같은 것으로 보는 ‘약한 검사기(weak validator)’를 지원
    * 서버는 ‘W/‘ 접두사로 약한 검사기를 구분
    * Etag: W/“v2.6"
    * If-None-Match: W/“v2.6"
* 강한 검사기(strong validator)는 콘텐츠가 바뀔 때마다 바뀐다.

#### 언제 엔티티 태그를 사용하고 언제 Last-Modified 일시를 사용하는가
서버가 반환해준 것에 따라 적절한 검사를 사용해야 한다.
* 만약 모두 사용가능하다면, 1.0과 1.1 캐시 모두 적절히 응답할 수 있도록 클라는 각각을 위해 두 가지의 재검사 정책을 모두 사용
* 1.1 캐시나 서버가 If-Modified-Since와 엔티티 태그 조건부 헤더를 모두 받았다면 모든 조건에 부합되지 않는 한 304 응답을 반환해서는 안 된다.

### 캐시 제어
HTTP는 문서가 만료되기 전까지 얼마나 오랫동안 캐시될 수 있게 할 것인지 서버가 설정할 수 있는 여러 가지 방법을 정의한다. 우선순위는 다음과 같다.
* Cache-Control: no-store
* Cache-Control: no-cache
* Cache-Control: must-revalidate
* Cache-Control: max-age
* Expires 날짜 헤더
* 아무런 정보도 주지 않고, 휴리스틱 방법으로 결정하게 할 수 있다.

#### no-cache와 no-store 응답 헤더
No-store와 no-cache 헤더는 캐시가 검증되지 않은 캐시된 객체로 응답하는 것을 막는다.
* ’no-store’가 표시된 응답은 캐시가 응답의 사본을 만드는 것을 금지.
    * 클라에게 no-store 응답을 전달하고 나면 객체를 삭제할 것이다.
* ’no-cache’로 표시된 응답은 로컬 캐시 저장소에 저장될 수 있다.
    * 다만 먼저 재검사를 하지 않고는 클라에게 제공될 수 없을 뿐이다.

#### Max-Age 응답 헤더
신선하다고 간주되었던 문서가 서버로부터 온 이후로 흐른 시간이고, 초로 나타낸다.
* s-maxage 헤더는 max-age처럼 행동하지만 공유된(공용) 캐시에만 적용

#### Expires 응답 헤더
deprecated 되기를 권하는 Expires 헤더는 초 단위의 시간 대신 실제 만료 날짜를 명시

#### Must-Revalidate 응답 헤더
캐시는 성능을 개선하기 위해 신선하지 않은(만료된) 객체를 제공하도록 설정될 수 있다. 만약 만료 정보를 엄격하게 다르길 원한다면, 원 서버는 Cache-Control: must-revalidate를 보내면 된다.
* 신선하지 않은 사본을 원 서버와의 최초의 재검사 없이는 제공해서는 안됨
* 재검사 했을 때 원 서버가 사용할 수 없는 상태라면 504 Gateway Timeout error를 반환

#### 휴리스틱 만료
응답이 Cache-Control: max-age 헤더나 Expires 헤더 중 어느 것도 포함하지 않고 있다면, 캐시는 경험적인 방법(heuristic) 최대 나이를 게산할 것이다.
* 어떤 알고리즘이든 사용될 수 있지만, 계산 결과 얻은 최대 나이 값이 24시간보다 크다면, Heuristic Expiration 경고(경고 13) 헤더가 응답 헤더에 추가되어야 한다.

유명한 휴리스틱 만료 알고리즘의 하나인 LM 인자 알고리즘은, 최근 변경 일시를 포함하고 있다면 사용할 수 있다.
* 캐시된 문서가 변경된 것이 상단히 예전이라면, 그것은 아마 안정적일 문서일 것이라고 판단
* 최근에 변경되었다면, 그것은 아마 자주 변경될 것이라고 판단하고 짧은 기간동안에만 캐시
* 최근 변경일이 없다면, 기본 신선도 유지기간을 설정(보통 한 시간이나 하루, 더 보수적이면 0의 신선도 수명)

#### 클라이언트 신선도 제약
브라우저나 프락시 캐시의 신선하지 않은 콘텐츠를 강제로 갱신시켜 주는 리프레시나 리로드 버튼을 갖고 있다.
* Cache-Control 요청 헤더가 추가된 GET 요청을 발생시켜서, 강제로 재검사하거나 서버로부터 콘텐츠를 무조건 가져온다.
* 정확한 리프레시 동작은 각 브라우저나 문서, 중간 캐시 설정에 달려 있다.

#### 주의할 점
문서 만료는 완벽한 시스템이 아니다.
* 잘못해서 유효기간을 까마득한 미래로 설정해버린다면, 만료되기 전까지 그 문서에 대한 어떤 변경도 캐시에 반영되지 않는다.
* 아예 유효기간을 사용조차 하지 않아서, 문서가 얼마나 오랫동안 신선할 것인지 캐시가 알기 어렵게 되는 경우도 많다.

### 자세한 알고리즘

#### 나이와 신선도 수명
캐시된 문서가 제공하기에 충분히 신선한지 알려주려면, 캐시된 사본의 나이와 신선도 수명만 계산하면 된다.
* 만약 캐시된 사본의 나이가 신선도 수명보다 작으면 사본은 제공해주기에 충분히 신선한 것이다.
* Age 헤더를 통해 명시적으로(추천) 서버가 생성한 Date 헤더를 통해 계산하든 간에 문서의 나이를 판별해야 한다.

#### 나이 계산
응답의 나이는 응답이 서버에서 생성되었을(혹은 재검사) 때부터 지금까지의 총 시간
* 그 나이는 응답이 인터넷상의 라우터들과 게이트웨이들 사이를 떠돌아다닌 시간과 응답이 캐시에 머물렀던 시간을 포함
* 캐시는 얼마나 캐시되었는지 아주 쉽게 알아낼 수 있지만, 캐시에서 온 응답의 나이를 알아내는 것은 어렵다.
    * 모든 서버가 동기화된 시계를 갖고 있지 않으며 우리는 응답이 어디에서 왔는지도 모르기 때문

겉보기 나이는 Date 헤더에 기반한다.
* 서버에서 보내주는 Date 헤더값이 문서의 ‘겉보기 나이’가 될 것이다.
* 모든 서버들의 시계가 잘 동기화 되어 있지 않다.
    * 서버, 프락시가 서로 동일한 시간축을 갖도록 NTP와 같은 동기화 프로토콜을 사용할 것을 권한다.
* 두 컴퓨터의 시계 설정 차이로 인한 문제를 클록 스큐라고 한다.
* 클록 스큐 때문에 나이가 음수가 되는 일이 있다면 그것을 0으로 만들어야 한다.

점층적 나이 계산
*  클록 스큐로 인한 정확도 손실 전반에 대해 할 수 있는 일이 별로 없다.
* HTTP/1.1은 동기화된 시계가 존재하지 않아서 우회책으로 프락시나 캐시를 통과할 때마다 그 장치들이 Age 헤더에 상대적인 나이를 누적해서 더하도록 한다.
* 응답 체인에 있는 비 HTTP/1.1은 Age 헤더를 인식하지 못할 수 있다.
* 상대 나이 값은 Date 기반 나이와는 별개로 계산되어, 두 나이 추정값 중 보수적인(가장 큰) 것이 선택된다.
    * 더 신선한 콘텐츠를 얻을 수만 있다면 Age 헤더의 오류도 용인한다.

네트워크 지연에 대한 보상
* 트랜잭션은 느려질 수 있다.
* 매우 느린 네트워크나 과부하가 걸린 서버에서는 상대 나이 계산은 문서의 나이에 대한 상당히 모자란 추정이 될 수 있다.
* HTTP/1.1은 왕복 지연을 계산하여 더함으로써 네트워크 지연을 보수적으로 교정한다.
    * 언제 문서를 요청했고 언제 응답을 받았는지를 계산

#### 완전한 나이 계산 알고리즘
언제 문서가 캐시에 도착했는지 알고 있고(응답을 받은 시간) 언제 현재 요청이 도착했는지 안다(바로 지금).
* 따라서 체류시간은 정확히 둘의 차와 같다.

#### 신선도 수명 계산
신선도 수명은 문서가 특정 클라이언트에게 제공해주기에는 더 이상 신선하지 않게 될 때까지 얼마나 오랜 시간 동안 가져올 수 있도록 허용하는지 말해준다.
* 신선도 수명은 서버와 클라의 제약조건에 의존
    * 서버는 문서가 얼마나 자주 변경되어 발행되는지에 대한 정보를 갖고 있다(수년이든 몇개월이든)
    * 클라는 약간 신선하지 못한 콘텐츠도 받아들이려 할 수 있고, 최신의 콘텐츠만 요구할 수도 있다.

### 캐시와 광고

#### 광고 회사의 딜레마
캐시가 잘 되어 있다면 같은 데이터를 방문자들에게 보이기 위해 터무니 없는 네트워크 서비스 요금을 지불할 필요가 없다.
* 캐시가 빠르면서도 더 잘 보여줌으로써, 그들이 더 많은 콘텐츠를 소비하고 더 많은 광고를 보게 할 수 있다.
* 그러나 콘텐츠 제공자가 광고를 통해 돈을 버는데 만약 캐시가 그 접근들을 모두 흡수하고 원 서버 접근 횟수에 따라 돈을 번다면, 이는 달갑지 않다.

#### 퍼블리셔의 응답
오늘날 광고회사들은 캐시가 광고 시청 수를 가로채지 못하도록 모든 종류의 ‘캐시 무력화’ 기법을 사용한다.
* 광고를 CGI 게이트웨이를 통해 제공하는데, 매 접근마다 광고 URL을 고쳐 쓴다.
* 이상적으로는, 콘텐츠 제공자는 캐시가 그들의 트래픽을 흡수하도록 내버려 두어야 하며, 캐시는 그들에게 적중이 얼마나 일어났는지 알려주어야 한다.
* 한 가지 방법은 모든 접근에 대해 원 서버와 재검사하도록 캐시를 설정하는 것
    * 매 접근마다 캐시 적중이 있었음을 알리지만 본문 데이터를 전송하지 않는다. 물론 이는 트랜잭션을 느리게 만듬

#### 로그 마이그레이션
이상적인 해결책 하나는 서버로 요청이 가지 않도록 하는 것
* 캐시는 모든 적중의 로그를 유지할 수 있다.
* 캐시 제공자들이 로그를 수동으로 처리해서 직접 건네줄 수 있다.
    * 불행히도, 적중 로그는 그 크기 때문에 옮기기 어렵다.
    * 캐시 로그는 표준화되어 있지도 조직되어 있지도 않다.
    * 인증과 프라이버시 이슈도 있다.
* 효율적인 로그 재분산을 위한 전략들이 제안되어 왔지만 충분히 발전된 것은 없다.
    * 대부분 극단적으로 복잡하고 효과를 보려면 공동 사업 협력이 필요하다.

#### 적중 측정과 사용량 제한
HTTP에 때때로 특정 URL에 대한 캐시 적중 횟수를 정기적으로 서버에게 돌려주는 Meter라고 하는 새 해더를 추가
* 서버가 캐시된 문서가 적중한 횟수의 정기적인 업데이트를 캐시로부터 받는다.
* 추가적으로 서버는 캐시가 서버에게 보고해야 하기 전까지, 문서를 제공할 수 있는 횟수나 소모할 수 있는 처리시간을 제어할 수 있다.
    * 이를 사용량 제한이라고 부른다.